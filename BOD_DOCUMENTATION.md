# New User & BOD Process User Guide

## This Document Includes

This document provides a complete, step-by-step guide for new users and developers to understand and work with the BOD process.

It includes:


- How to add a new file to the BOD process  
- How to add a new process to the BOD execution flow  
- How to verify changes using the UI  
- Common mistakes and how to avoid them  
- What to do if a BOD process fails  


This section explains the **project folder structure** and describes **exactly where and how a new file-parsing script should be added** so that it becomes part of the BOD process.

If you want to add a new file to the BOD flow, **this is the first section you must read**.

## 1.1 High-Level Project Structure

At the root level, the project contains the following important items:

```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ lib/
‚îÇ ‚îú‚îÄ‚îÄ config.py
‚îÇ ‚îú‚îÄ‚îÄ email.py
‚îÇ ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ ‚îú‚îÄ‚îÄ (multiple BOD and EOD scripts)
‚îÇ
‚îú‚îÄ‚îÄ process_master.py
‚îú‚îÄ‚îÄ process.json
‚îî‚îÄ‚îÄ requirement.txt
```



Each of these plays a specific role in the BOD process.

---

## 1.2 Purpose of Each Folder and File

### 1.2.1 `lib/` Folder (Shared Utilities)

The `lib` folder contains **shared support files** used by all BOD and EOD scripts.

```
lib/
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ email.py
‚îî‚îÄ‚îÄ logger.py
```

**What this folder is for:**
- Common configuration values
- Common logging behavior
- Common alert or notification handling

**Important rules:**
- New BOD scripts should **use** these files
- New BOD scripts should **not duplicate** logic already present here
- This folder should not contain business logic for individual files

üìå Think of this folder as **system support**, not processing logic.

---

### 1.2.2 `utils/` Folder (Actual BOD & EOD Work)

The `utils` folder contains **all scripts that perform real BOD and EOD work**.

This is where **new file-parsing scripts must be added**.

üì∏ **Screenshot Placeholder**  
> utils folder showing existing BOD and EOD scripts

From the existing structure, you can observe:
- Each file handles **one specific responsibility**
- Most files are named clearly based on what they do
- Each script is designed to run independently

---

### 1.2.3 `process_master.py` (Central Runner)

`process_master.py` is the **central controller** of the system.

**What it does:**
- Reads `process.json`
- Identifies which processes exist
- Decides execution order
- Executes scripts from the `utils` folder
- Updates execution status for the UI

‚ö†Ô∏è Important:
- You **never add logic directly** into `process_master.py`
- You only **register** new scripts so that `process_master.py` can execute them

---

### 1.2.4 `process.json` (Process Registration File)

`process.json` is the **most important configuration file** for BOD.

**What it defines:**
- Which scripts are part of BOD
- Execution order
- Script locations
- Required parameters

If a script is **not present in `process.json`**, it will:
- Never run
- Never appear in the UI
- Never be part of BOD

---

### 1.2.5 `requirement.txt`

This file lists all required dependencies for the project.

**Rules:**
- If your new script requires something new, it must be added here
- Existing scripts rely on this file to work consistently


## 1.3 Script Responsibilities (Purpose, Input, Output & Dependencies)

### üìÑ Script: download_nse_most_active_scripts.py

`copy_files_src_dst.py` is a **foundational pre-processing script** in the BOD workflow.
Its sole responsibility is to **guarantee the availability of input files and directories**
at the correct locations **before any downstream processing begins**.

In a production BOD system, the most frequent causes of failure are not code issues,
but operational issues such as:
- input files arriving late or in unexpected locations
- files being required by multiple downstream processes
- partial or inconsistent file availability

This script is designed to **isolate and eliminate these risks** by acting as a
**gatekeeper for file availability**.

### üìÑ Script: db_backup.py

`db_backup.py` is a **critical safety and risk-mitigation script** in the BOD workflow.
Its primary purpose is to create a **consistent, recoverable backup of the database**
*before any BOD process modifies data*.

In production BOD systems, data corruption or partial updates can occur due to:
- unexpected script failures
- incorrect input data
- infrastructure or network issues

This script ensures that a **known-good database state** is always available for recovery
in case any downstream BOD step fails.

> üîí This script must always run **before** any database-modifying BOD scripts.
---

### 2Ô∏è‚É£ Execution Context

The script is designed as a **standalone command-line utility** and can be executed in two ways:

- Automatically by `process_master.py` during the BOD startup phase
- Manually by operations or developers for emergency or ad-hoc backups

The script performs **read-only operations** on the database and does not depend on
any external application state.

---

`docker exec <mysql_container> mysqldump ...`

3Ô∏è‚É£ Runtime Dependencies

#### 3.1 System-Level Dependencies

The following must be available at runtime:

- Docker installed and running
- MySQL Docker container running
- `mysqldump` available inside the container
- `gzip` available for compression

If any of these dependencies are missing, the script will fail.

#### 3.2 Python Dependencies

The script uses only Python standard library modules:

- `os` ‚Äì directory validation and file handling
- `subprocess` ‚Äì command execution and piping
- `datetime` ‚Äì timestamp generation
- `sys` ‚Äì platform checks
- `argparse` ‚Äì command-line argument parsing

  #### Required Arguments
- `--user` : MySQL username  
- `--password` : MySQL password  
- `--database` : Database name (ignored if `--all-databases` is used)  
- `--output_dir` : Directory where backup files are stored  

- `--host` (default: `localhost`)
- `--port` (default: `3306`)
- `--all-databases` : Backup all databases instead of a single database
- `--no_compress` : Disable gzip compression
- `--mysql_container_name` (default: `blitz_mysql`)
---
### üìÑ Script: db_backup.py

## 1Ô∏è‚É£ Purpose and Design Intent

`db_clean.py` is a **database preparation and hygiene script** executed during the early
phase of the BOD workflow.  
Its primary responsibility is to ensure that the database is in a **clean, predictable state**
before fresh BOD data is loaded.

Unlike a full database reset, this script supports **two controlled cleanup strategies**:
1. **Hard cleanup (TRUNCATE)** ‚Äì permanently removes all data from selected tables
2. **Soft cleanup (DELETE WHERE IsDeleted = TRUE)** ‚Äì removes logically deleted rows only

This dual-mode design allows the system to:
- preserve important reference or configuration data
- safely remove stale or transient records from previous runs
- avoid unintended data loss

> This script must always run **after `db_backup.py`**  
>  This script must run **before any data ingestion or upload scripts**

### 2Ô∏è‚É£ Execution Context

The script is implemented as a **standalone command-line utility** and can be executed:

- Automatically by `process_master.py` as part of the BOD flow
- Manually by operations or developers for controlled database cleanup

The script performs **write operations** on the database and therefore must be treated
as a **high-impact script**.
### 3Ô∏è‚É£ Runtime Dependencies

#### 3.1 System and Environment Dependencies

- MySQL database must be running and accessible
- Network connectivity to the database host
- Sufficient privileges to:
  - TRUNCATE tables
  - DELETE rows
  - READ table metadata

---

#### 3.2 Python Dependencies

This script depends on:

- `mysql-connector-python`  
  (must be installed via `pip install mysql-connector-python`)

Standard library modules:
- `argparse` ‚Äì command-line argument parsing

4Ô∏è‚É£ Input Contract (Command-Line Arguments)

The script relies entirely on explicit command-line inputs.

#### Required Arguments
- `--user` : Database username  
- `--password` : Database password  
- `--database` : Database name  
- `--host` (default: `localhost`)
- `--port` (default: `3306`)
- `--tables`
- `--blitz_server` (currently informational)


## üìÑ Script : download_and_process_bhavcopy.py
`download_and_process_bhavcopy.py` is a **core market data ingestion script** in the BOD workflow.
Its primary responsibility is to **download, extract, validate, and process daily NSE Bhavcopy data**
and make it available for downstream analytics, reporting, and trading-related processes.

This script acts as the **single source of truth for daily market reference data**, including:
- Cash Market (CM) equity prices
- Futures & Options (FO) contract data
- Index OHLC data (e.g., NIFTY 50, BANK NIFTY)

>  This script should be executed **after market close**  
>  Downstream systems rely on the correctness of this data

### 2Ô∏è‚É£ Data Sources (From Where the Files Are Downloaded)

This script downloads data **only from official NSE-controlled endpoints**.
No third-party or intermediary data providers are used.

---

#### 2.1 NSE Bhavcopy Files (CM & FO)

**Primary domain:**
[https://nsearchives.nseindia.com](https://nsearchives.nseindia.com)
#####  Cash Market (CM) Bhavcopy
[https://nsearchives.nseindia.com/content/cm/](https://nsearchives.nseindia.com/content/cm/)
`BhavCopy_NSE_CM_0_0_0_<YYYYMMDD>_F_0000.csv.zip`


**URL pattern:**
**Contains:**
- Equity OHLC prices
- Traded volume and value
- Settlement prices

---

##### üìå Futures & Options (FO) Bhavcopy

**URL pattern:**
[https://nsearchives.nseindia.com/content/fo/](https://nsearchives.nseindia.com/content/fo/)
`BhavCopy_NSE_FO_0_0_0_<YYYYMMDD>_F_0000.csv.zip`

**Contains:**
- Futures and Options contracts
- Expiry dates, strike prices
- Volume, Open Interest, settlement prices

---

#### 2.2 Index OHLC Data

Index data is fetched using an NSE-backed API hosted on:
[https://www.niftyindices.com](https://www.niftyindices.com)
**API Endpoint:**
[https://www.niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString](https://www.niftyindices.com/Backpage.aspx/getHistoricaldatatabletoString)
### 3Ô∏è‚É£ Execution Context

The script is designed as a **standalone executable utility** and can be run:

- Automatically via `process_master.py` during BOD
- Manually for validation, reprocessing, or historical backfill

The script performs **both network I/O and database writes**, making it a **high-impact script**.

---
### 4Ô∏è‚É£ Runtime Dependencies
The script depends on **live availability of official NSE services**.

Mandatory external endpoints:
- `https://nsearchives.nseindia.com`  
  (For CM & FO Bhavcopy ZIP files)
- `https://www.niftyindices.com`  
  (For index OHLC data API)

SE enforces request filtering and anti-bot mechanisms.

The script **explicitly depends on**:
- Valid `User-Agent` header
- Valid `Referer: https://www.nseindia.com/`
- Persistent HTTP session usage

If headers are modified or removed:
- NSE may return HTTP 403 / 401
- Download will fail even if URL is correct

### 5Ô∏è‚É£ Failure Handling and Edge Cases

#### Common Failure Scenarios
- NSE endpoint unavailable
- Bhavcopy not yet published for the day
- Partial or corrupt ZIP downloads
- CSV format changes
- Database connectivity issues

#### Failure Behavior
- Script logs detailed error messages
- Processing stops on critical failures
- No partial database writes are committed

This ensures **data integrity and consistency**.

---
## üìÑ Script: download_banned_instruements.py
### 1Ô∏è‚É£ Purpose and Design Intent

`download_banned_instruements.py` is a **regulatory compliance and risk-control script**
executed as part of the BOD workflow.

Its primary responsibility is to:
- Download the **official NSE list of banned F&O instruments**
- Persist the data into the internal database
- Ensure the trading system is aware of instruments that must be blocked

This script directly supports **exchange compliance**, **risk management**, and
**order validation logic**.

> üîí If this script is skipped or fails, the system may allow trading
> in instruments that are officially banned by the exchange.

---
### 2Ô∏è‚É£ Data Source (From Where the File Is Downloaded)

The script downloads data **directly from an official NSE archive endpoint**.

#### üì• Source URL
[https://nsearchives.nseindia.com/content/fo/fo_secban.csv](https://nsearchives.nseindia.com/content/fo/fo_secban.csv)
#### üìÑ File Description
- File Name: `fo_secban.csv`
- Published by: **National Stock Exchange (NSE)**
- Update Frequency: Daily (post exchange updates)
- Content Type: CSV

#### üìå File Contents
| Column | Description |
|-----|-------------|
| Index | Row index (not used in DB) |
| Symbol | Trading symbol banned by NSE |

This file represents the **authoritative list** of banned F&O instruments.

---

### 3Ô∏è‚É£ Execution Context

The script is implemented as a **standalone CLI utility** and is executed:

- Automatically via `process_master.py` during BOD
- Manually for validation or recovery

The script performs **both network I/O and database writes**, making it
**high-impact and non-optional** in the BOD flow.

---
### 4Ô∏è‚É£ Genuine Runtime Dependencies (Actual & Enforced)

This script has **hard, non-negotiable dependencies** that must be satisfied.

---

#### 4.1 External Network Dependencies

- Internet connectivity must be available
- NSE archive endpoint must be reachable:

[https://nsearchives.nseindia.com](https://nsearchives.nseindia.com)
- Host IP must not be blocked by NSE

The script depends on:
- A valid `User-Agent` header
- Direct HTTP GET access

If NSE blocks the request:
- HTTP 403 / 401 is returned
- Script fails immediately

---
#### 4.3 Database Dependencies (Hard Requirement)

The script performs **direct INSERT operations** into MySQL.

Required conditions:
- MySQL server must be running
- Database must be reachable
- Target database must exist
- Table `BannedInstruments` must exist
- DB user must have `INSERT` privilege

Expected table schema (minimum):
```sql
BannedInstruments(
Symbol VARCHAR(...),
Reason VARCHAR(...),
IsBanned BOOLEAN,
IsUserCreated BOOLEAN
)
If table or privileges are missing:

Script fails during insertion

No fallback logic exists
```

## üìÑ Script Deep Dive: download_bse_contract_master.py

---

### 1Ô∏è‚É£ Purpose and Business Intent

`download_bse_contract_master.py` is a **reference data acquisition script**
used in the BOD workflow to download and prepare **BSE contract master files**
required for instrument mapping and downstream processing.

Its primary responsibility is to:
- Download **official contract reference files** from BSE
- Extract and normalize filenames into **fixed, predictable names**
- Ensure downstream scripts can consume BSE reference data
  without handling date-based filenames

This script does **not** parse or load data into the database.
It strictly prepares **clean, standardized input files**.

---

### 2Ô∏è‚É£ Authoritative Data Sources (From Where the Files Are Downloaded)

All data is downloaded **directly from official BSE-controlled endpoints**.

#### üì• Source 1: SCRIP Master File

**URL:**
[https://www.bseindia.com/downloads/Help/file/scrip.zip](https://www.bseindia.com/downloads/Help/file/scrip.zip)


**Provided by:**  
:contentReference[oaicite:1]{index=1}

**Contents after extraction:**
- Folder: `SCRIP/`
- File pattern:
SCRIP_<ddMMyy>.TXT


This file contains **BSE instrument reference data**
(e.g. scrip codes, symbols, ISINs).

---

#### üì• Source 2: EQD (Equity Details) File

**URL:**


[https://www.bseindia.com/downloads1/CO_BSE.zip](https://www.bseindia.com/downloads1/CO_BSE.zip)
**Contents after extraction:**
- File pattern:
EQD_CO<ddMMyy>.csv

yaml
Copy code

This file contains **BSE equity master information**
used for equity-level mapping.

---

### 3Ô∏è‚É£ Execution Context

The script is implemented as a **standalone CLI utility** and is executed:

- Automatically via `process_master.py` during BOD
- Manually for recovery, testing, or file regeneration

The script performs:
- External network downloads
- ZIP extraction
- File renaming and movement

It does **not**:
- Modify databases
- Touch Redis
- Depend on other BOD scripts

---

### 4Ô∏è‚É£ Date Resolution Logic (Important)

The script resolves filenames using:
current_date - 1 day

yaml
Copy code

Reason:
- BSE publishes contract files **with previous trading date**
- Running the script on the same day before file publication
  would result in missing files

‚ö†Ô∏è This introduces a **time dependency**:
- Script should be run **after BSE publishes files**
- Weekend / holiday execution may require manual verification

---

### 5Ô∏è‚É£ Failure Handling and Edge Cases

#### 5.1 BSE Endpoint Unavailable
- HTTP request fails
- Script exits with non-zero code
- No files prepared

---

#### 5.2 ZIP Downloaded but Not a Valid ZIP
- Script checks `zipfile.is_zipfile`
- If invalid, extraction is skipped
- Downstream file rename fails

---

#### 5.3 Date-Based File Not Found
- Expected dated file does not exist
- Rename step is skipped silently
- Output files (`SCRIP.TXT`, `EQD.csv`) are missing

This may break downstream consumers.

`download_bse_contract_master.py` prepares authoritative BSE contract reference files
by downloading them from official BSE endpoints, extracting them, and normalizing
their filenames for downstream consumption.  
Its behavior is highly dependent on BSE publication timing and file naming conventions,
and it plays a critical role in ensuring reliable BSE instrument reference data
for the entire BOD workflow.

## üìÑ Script Deep Dive: download_contract_master.py

---

### 1Ô∏è‚É£ Purpose and Business Intent

`download_contract_master.py` is a **core reference-data ingestion script**
responsible for downloading the **NSE Contract Master files** required for
instrument definition, validation, and downstream market-data processing.

Its primary responsibilities are:
- Authenticate with NSE‚Äôs secure extranet API
- Download **compressed contract master files**
- Decompress and normalize them into usable text files
- Store raw compressed data in Redis for fast access and audit

This script is **foundational** for any system that relies on:
- Instrument master data
- Contract definitions
- Symbol‚Äìtoken‚Äìexpiry mappings

> üîí If this script fails, **instrument-related processing must not proceed**.

---

### 2Ô∏è‚É£ Authoritative Data Source (From Where the Files Are Downloaded)

This script downloads data from **NSE‚Äôs official secure extranet APIs**.

**Provided by:**  
:contentReference[oaicite:1]{index=1}

---

#### 2.1 Base API Endpoints
Base URL : [https://www.connect2nse.com/extranet-api](https://www.connect2nse.com/extranet-api)

```Login API : /login/2.0
File Download API : /common/file/download/2.0


```


These endpoints are **authenticated**, **member-restricted**, and **not public**.

---

#### 2.2 Files Downloaded

The script downloads the following **compressed reference files**:

| File Name | Segment | Folder Path | Description |
|---------|--------|------------|-------------|
| `security.gz` | CM | `/ntneat` | Security master data |
| `contract.gz` | CM | `/ntneat` | Contract master data |

Both files are published and maintained by NSE and represent the
**authoritative contract definitions**.

---

### 3Ô∏è‚É£ Authentication Model (Critical Dependency)

Before any download, the script performs an **authenticated login**.

**Login API:**
POST [https://www.connect2nse.com/extranet-api/login/2.0](https://www.connect2nse.com/extranet-api/login/2.0)
**Required credentials:**
- `memberCode`
- `loginId`
- `encryptedPassword`

On successful login:
- NSE returns a **Bearer token**
- The token is stored in memory and used for all download requests

If authentication fails:
- No file download is attempted
- Script exits immediately

### 4Ô∏è‚É£ Execution Context

The script is implemented as a **standalone CLI utility** and is executed:

- Automatically via `process_master.py` during BOD
- Manually for validation, re-runs, or recovery

The script performs:
- Secure network calls
- File system writes
- GZIP decompression
- Redis writes

Because of this, it is considered a **high-impact infrastructure script**.


## 1.4 First Step: Writing a New File-Parsing Script

If you want to parse a **new file** as part of BOD, follow these steps.

---

### Step 1: Identify the File Clearly

Before writing any code, identify:
- File name pattern
- Fixed daily location
- Purpose of the file
- Whether other processes depend on it

This helps decide **where it fits in the BOD order**.

---

### Step 2: Create a New Script Inside `utils/`

All new file-parsing scripts must be added inside the `utils/` folder.

Example naming rules:
- Name should clearly describe the file
- One script should handle **one file type only**


![utils](https://raw.githubusercontent.com/priyanshu-quantxpress/MD-files/main/images/utils.png)


> New script added inside utils folder



### Step 3: What the Script Is Expected to Do

Every script inside `utils/` must follow these responsibilities:

1. Locate the file from its expected location  
2. Validate that the file exists  
3. Validate basic file correctness  
4. Process the file content  
5. Exit clearly with success or failure  

‚ö†Ô∏è Important rules:
- Script must be runnable on its own
- Script must not assume other scripts have already run unless explicitly ordered
- Script must fail clearly if the file is missing or invalid


### 6Ô∏è‚É£ Input Contract (CLI Arguments)

| Argument | Required | Description |
|------|--------|-------------|
| `--member_code` | ‚úÖ | NSE member code |
| `--login_id` | ‚úÖ | NSE login ID |
| `--encrypted_password` | ‚úÖ | Encrypted NSE password |
| `--download_folder` | ‚ùå | Output folder (default: `downloads`) |

Missing any required argument causes **immediate script termination**.

`download_contract_master.py` securely downloads and prepares the NSE contract
and security master files using authenticated extranet APIs.
It enforces strict authentication, retry, and decompression logic while also
caching raw compressed data in Redis for performance and audit purposes.
The script is a critical dependency for all instrument-driven BOD processes
and must execute successfully for a valid trading day setup.

---


## üìÑ Script Deep Dive: download_nse_most_active_scripts.py

---

### 1Ô∏è‚É£ Purpose and Business Intent

`download_nse_most_active_scripts.py` is a **real-time market snapshot ingestion script**
used to fetch **NSE ‚ÄúMost Active / Gainers‚Äù market data** and store it in Redis for
fast, in-memory consumption.

Its primary objective is to:
- Download live market CSV data from NSE APIs
- Store the raw CSV response in Redis
- Make the data instantly available for UI, analytics, or monitoring use cases

This script is **read-only with respect to NSE data** and **write-only with respect to Redis**.

> üîí This script does **not** modify databases  
> üîí It acts as a lightweight data feeder for real-time views

---

### 2Ô∏è‚É£ Authoritative Data Source (From Where the Data Is Downloaded)

The script fetches CSV data from an **official NSE public API endpoint**.

**Primary API Endpoint:**
[https://www.nseindia.com/api/live-analysis-variations?index=gainers&type=NIFTY&csv=true](https://www.nseindia.com/api/live-analysis-variations?index=gainers&type=NIFTY&csv=true)

yaml
Copy code

**Provided by:**  
:contentReference[oaicite:1]{index=1}

---

#### üìå Nature of the Data

- Format: CSV
- Data Type: Live / near-real-time market snapshot
- Segment: Equity (NIFTY index gainers)
- Update Frequency: Intraday (frequently updated by NSE)

‚ö†Ô∏è This data is **not end-of-day (EOD)** data and should not be treated as historical truth.

---

### 3Ô∏è‚É£ Execution Context

The script is implemented as a **standalone command-line utility** and can be executed:

- Automatically as part of auxiliary BOD/EOD or intraday jobs
- Manually for cache refresh or troubleshooting

The script performs:
- One HTTP GET request to NSE
- One Redis `SET` operation

It is intentionally **stateless and lightweight**.


### 4Ô∏è‚É£ Runtime Dependencies (Actual & Enforced)
- NSE public API must be reachable:
[https://www.nseindia.com](https://www.nseindia.com)




## 1.4 Registering the New Script in `process.json` 

This section explains **how file paths and locations are defined inside `process.json`**
and **why paying attention to paths is the most critical part of adding a new BOD process**.

Most BOD failures do **not** happen because of script logic.
They happen because of **incorrect paths, wrong folders, or misunderstood locations**.

---

## What is `process.json`?

`process.json` is the **main configuration file** that defines the complete daily process flow.

It tells the system:
- which processes exist
- which scripts should be executed
- whether a process is BOD or EOD
- the order in which processes run
- where scripts are located
- where input files are expected
- where output files should be written

If a script or file path is **not defined here**, it will **never run**.

---

## Understanding `base_path`

At the top of `process.json`, there is a field called `base_path`.

Example:

  `base_path: C:\Users\Navin Kumar\Desktop\QXT\1 New Blitz Projects\Backend\QX.ProcessManager\utils`

  ### What `base_path` means
- It is the **common folder** where most processing scripts are stored
- It avoids repeating long folder paths again and again

### When to use `base_path`
Use `${base_path}` when:
- your script is placed inside the `utils` folder
- your script is part of the regular BOD or EOD flow

Example:

`"application_path": "${base_path}\copy_files_src_dst.py"`




This means:
> Run `copy_files_src_dst.py` from the `utils` folder.

---

## Understanding `application_path`

`application_path` defines **exactly which script will be executed**.

Examples:
`"${base_path}\download_nse_most_active_scripts.py"`


### Rules for `application_path`
- It must be a **full absolute path**
- It must point to **one script file**
- The script must exist at that location
- File name and folder name must match exactly

If `application_path` is wrong:
- the script will not start
- the process will fail immediately

---

## Where Input Files Should Be Placed

Input file locations are usually passed inside the `parameter` section.

Example:

`"parameter": {
"source":"C:\Users\Navin Kumar\Desktop\QXT\Backend\QX.ProcessManager\downloads\nsccl.20250627*"
}`


### What this means
- The script will look for input files in this folder
- File names must match the given pattern
- Files must already exist before the process runs

### Rules for input file paths
- Use a **fixed folder** for incoming files
- Files should arrive in the same location every day
- File name format should be consistent
- Do not change paths daily

---

## Destination Paths (Output Files)

Some scripts copy or generate files and need a destination folder.

Example:
`
"destination": [
"C:\Users\Navin Kumar\Desktop\QXT\BOD Project\"
]
`

### Rules for destination paths
- The folder must exist or be created by the script
- Use separate folders for output files
- Do not overwrite unrelated files

---

## Path Format Rules (Very Important)

Always follow these rules while writing paths:

- Use **absolute paths only**
- Use double backslashes `\\`
- Do not use relative paths
- Do not add extra spaces
- Avoid temporary folders unless required

Correct:
`C:\\Users\\Navin Kumar\\Deskto\\QXT\\Backend\\QX.ProcessManager\\downloads`



---

## Next Step: Verifying the New Process from the UI

After adding or updating a process, verification is mandatory.

---

### Step 1: Restart the System

Changes in `process.json` are loaded only at startup.

- Stop the running system
- Start it again using the main runner (run `process_master.py`)

If this step is skipped, the new process will not appear.

---

### Step 2: Open the UI

- Open the Admin UI
- Navigate to Monitor Section 
- Navigate to the BOD/EOD section

You should see the new process listed.

![AdminUI](https://raw.githubusercontent.com/priyanshu-quantxpress/MD-files/main/images/AdminUI.png)

> UI showing the BOD process list

---

### Step 3: Verify the Process Details

Confirm:
- Process name is correct
- Execution order is correct
- Process is marked active

If anything looks wrong, stop and fix `process.json`.

---

### Step 4: Run BOD and Observe

- Trigger the BOD run
- Watch the process execution
- Ensure the process runs at the expected time
- Confirm it completes successfully

![RunBOD_EOD](https://raw.githubusercontent.com/priyanshu-quantxpress/MD-files/main/images/RunBOD_EOD.png)


> UI showing successful execution of the new process

---

### Step 5: If the Process Fails

If the process fails:
1. Check file availability
2. Verify input paths
3. Review logs
4. Fix the issue
5. Restart the system
6. Run BOD again

---

## Final Summary of the Flow



```
Script Added
‚Üì
Registered in process.json
‚Üì
System Restarted
‚Üì
Process Appears in UI
‚Üì
BOD Run Triggered
‚Üì
Process Executed

```


Following this flow ensures:
- Safe execution
- Predictable behavior
- Easy troubleshooting
